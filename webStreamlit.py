import streamlit as st
import streamlit.components.v1 as components
from streamlit_webrtc import WebRtcMode, webrtc_streamer
from typing import List, NamedTuple
import numpy as np
import pandas as pd
import requests
import re
import av
import cv2
import random
import logging
import time
import queue
from PIL import Image
from pathlib import Path
import urllib.request
from pyecharts.charts import *
from pyecharts import options as opts

#Pyechartså›¾è¡¨ç”Ÿæˆéœ€è¦ä¸€äº›é™æ€èµ„æºæ–‡ä»¶ï¼Œé€šè¿‡ä¸‹é¢ä»£ç æ›´æ”¹ä¸ºkesciæä¾›çš„èµ„æºï¼Œæé«˜åŠ è½½é€Ÿåº¦ï½
from pyecharts.globals import CurrentConfig
CurrentConfig.ONLINE_HOST = "https://cdn.kesci.com/lib/pyecharts_assets/"

image1 = Image.open('./icon/tea-garden.png')#è¯»å–å›¾æ ‡ä¸ºnp.arrayç±»å‹
#1ã€é…ç½®é¡µé¢çš„å…¨å±€ä¿¡æ¯
st.set_page_config(
    page_title="èŒ¶å›­ç®¡ç†ç³»ç»Ÿ",#é¡µé¢æ ‡é¢˜
    page_icon=image1,   #é¡µé¢å›¾æ ‡
    layout="wide",      #é¡µé¢å¸ƒå±€
    initial_sidebar_state="auto", #é¡µé¢ä¾§è¾¹æ 
)

#ä»Githubä¸‹è½½object-detection-appè®­ç»ƒå¥½çš„ç‰©ä½“æ£€æµ‹æ¨¡å‹model
HERE = Path(__file__).parent
ROOT = HERE.parent
logger = logging.getLogger(__name__)
MODEL_URL = "https://github.com/robmarkcole/object-detection-app/blob/master/model/MobileNetSSD_deploy.caffemodel"
MODEL_LOCAL_PATH = HERE / "./models/MobileNetSSD_deploy.caffemodel"
PROTOTXT_URL ="https://github.com/robmarkcole/object-detection-app/blob/master/model/MobileNetSSD_deploy.prototxt.txt"
PROTOTXT_LOCAL_PATH = HERE / "./models/MobileNetSSD_deploy.prototxt.txt"
#åˆ†ç±»
CLASSES = [
    "background",
    "aeroplane",
    "bicycle",
    "bird",
    "boat",
    "bottle",
    "bus",
    "car",
    "cat",
    "chair",
    "cow",
    "diningtable",
    "dog",
    "horse",
    "motorbike",
    "person",
    "pottedplant",
    "sheep",
    "sofa",
    "train",
    "tvmonitor",
]

def download_file(url, download_to: Path, expected_size=None):
    if download_to.exists():
        if expected_size:
            if download_to.stat().st_size == expected_size:
                return
        else:
            st.info(f"{url} is already downloaded.")
            if not st.button("Download again?"):
                return
    download_to.parent.mkdir(parents=True, exist_ok=True)
    weights_warning, progress_bar = None, None
    try:
        weights_warning = st.warning("Downloading %s..." % url)
        progress_bar = st.progress(0)
        with open(download_to, "wb") as output_file:
            with urllib.request.urlopen(url) as response:
                length = int(response.info()["Content-Length"])
                counter = 0.0
                MEGABYTES = 2.0 ** 20.0
                while True:
                    data = response.read(8192)
                    if not data:
                        break
                    counter += len(data)
                    output_file.write(data)
                    weights_warning.warning(
                        "Downloading %s... (%6.2f/%6.2f MB)"
                        % (url, counter / MEGABYTES, length / MEGABYTES)
                    )
                    progress_bar.progress(min(counter / length, 1.0))
    finally:
        if weights_warning is not None:
            weights_warning.empty()
        if progress_bar is not None:
            progress_bar.empty()

#ç”¨äºå­˜å‚¨å•ä¸€å®ä¾‹å¯¹è±¡çš„å‡½æ•°ä¿®é¥°å™¨ï¼›ç‰©ä½“æ£€æµ‹æ—¶ï¼Œæ ‡è®°é¢œè‰²
@st.experimental_singleton
def generate_label_colors():
    return np.random.uniform(0, 255, size=(len(CLASSES), 3))

COLORS = generate_label_colors()
download_file(MODEL_URL, MODEL_LOCAL_PATH, expected_size=23147564)
download_file(PROTOTXT_URL, PROTOTXT_LOCAL_PATH, expected_size=29353)
DEFAULT_CONFIDENCE_THRESHOLD = 0.5

class Detection(NamedTuple):
    name: str
    prob: float

# Session-specific caching
cache_key = "object_detection_dnn"
if cache_key in st.session_state:
    net = st.session_state[cache_key]
else:
    net = cv2.dnn.readNetFromCaffe(str(PROTOTXT_LOCAL_PATH), str(MODEL_LOCAL_PATH))
    st.session_state[cache_key] = net

def _annotate_image(image, detections):
    (h, w) = image.shape[:2]
    result: List[Detection] = []
    for i in np.arange(0, detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > confidence_threshold:
            # extract the index of the class label from the `detections`,
            # then compute the (x, y)-coordinates of the bounding box for
            # the object
            idx = int(detections[0, 0, i, 1])
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (startX, startY, endX, endY) = box.astype("int")
            name = CLASSES[idx]
            result.append(Detection(name=name, prob=float(confidence)))
            # display the prediction
            label = f"{name}: {round(confidence * 100, 2)}%"
            cv2.rectangle(image, (startX, startY), (endX, endY), COLORS[idx], 2)
            y = startY - 15 if startY - 15 > 15 else startY + 15
            cv2.putText(
                image,
                label,
                (startX, y),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                COLORS[idx],
                2,
            )
    return image, result
result_queue: queue.Queue = (
    queue.Queue()
)  # TODO: A general-purpose shared state object may be more useful.

def callback(frame: av.VideoFrame) -> av.VideoFrame:
    image = frame.to_ndarray(format="bgr24")
    blob = cv2.dnn.blobFromImage(
        cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5
    )
    net.setInput(blob)
    detections = net.forward()
    annotated_image, result = _annotate_image(image, detections)
    # NOTE: This `recv` method is called in another thread,
    # so it must be thread-safe.
    result_queue.put(result)  # TODO:
    return av.VideoFrame.from_ndarray(annotated_image, format="bgr24")

#è¯»å–videoè§†é¢‘
@st.experimental_singleton
def get_video_byte():
    video_file=open('./video/ç¦å»ºåŒ—è‹‘å¾¡èŒ¶å›­-ç®€ä»‹.mp4','rb')
    video_bytes1 = video_file.read()
    video_file.close()
    video_file = open('./video/ç¦å»ºè¯å®‰å…¬ç”°èŒ¶å›­-èˆªæ‹.mp4', 'rb')
    video_bytes2 = video_file.read()
    video_file.close()
    return video_bytes1, video_bytes2

#è·å–åŸå¸‚IDï¼Œä½œä¸ºè·å–åŸå¸‚å¤©æ°”çš„å‚æ•°
@st.cache(ttl=3600)
def get_city_mapping():
    datas=pd.read_csv(r"./icon/China-City-List-latest.csv",sep=',',header=1,usecols=[0,2,7,9],encoding='utf-8')
    data=dict(zip(datas['Adm2_Name_ZH'],datas['Location_ID']))
    fuzhou=0
    for i in data.keys():
        if i!='ç¦å·å¸‚':
            fuzhou += 1
        else:
            break
    return data,fuzhou

#åœ¨ç¼“å­˜ä¸­ä¿ç•™æ¡ç›®çš„æœ€å¤§ç§’æ•°,è·å–åŸå¸‚å¤©æ°”
@st.cache(ttl=3600)
def get_city_weather(ID):
    url=f"https://devapi.qweather.com/v7/weather/24h?location={ID}&key=05892c272b4f4a67b5ab30b7b95cdb9d"
    datas=requests.get(url).json()
    data_updateTime = datas['updateTime'] #apiæ›´æ–°æ—¶é—´
    forecastHours=[]
    for i in range(len(datas['hourly'])):
        tmp={}
        tmp['fxTime']=datas['hourly'][i]['fxTime'] #é¢„æŠ¥æ—¶é—´
        tmp['temp'] = datas['hourly'][i]['temp'] #æ¸©åº¦ï¼Œé»˜è®¤å•ä½ï¼šæ‘„æ°åº¦
        tmp['humidity'] = datas['hourly'][i]['humidity'] #ç›¸å¯¹æ¹¿åº¦ï¼Œç™¾åˆ†æ¯”æ•°å€¼
        tmp['windDir'] = datas['hourly'][i]['windDir'] #é£å‘
        tmp['windSpeed'] = datas['hourly'][i]['windSpeed'] #é£é€Ÿï¼Œå…¬é‡Œ/å°æ—¶
        tmp['precip'] = datas['hourly'][i]['precip'] #å½“å‰å°æ—¶ç´¯è®¡é™æ°´é‡ï¼Œé»˜è®¤å•ä½ï¼šæ¯«ç±³
        tmp['pressure'] = datas['hourly'][i]['pressure'] #å¤§æ°”å‹å¼ºï¼Œé»˜è®¤å•ä½ï¼šç™¾å¸•
        forecastHours.append(tmp)
    df_forecastHours=pd.DataFrame(forecastHours,columns=['fxTime','temp','humidity','windDir',
                                  'windSpeed','precip','pressure'])
    return data_updateTime,df_forecastHours

# åˆå§‹åŒ–å˜é‡
if 'first_visit' not in st.session_state:
    st.session_state.first_visit = True
else:
    st.session_state.first_visit = False
# åˆå§‹åŒ–å…¨å±€é…ç½®
if st.session_state.first_visit:
    st.session_state.city_mapping, st.session_state.random_city_index = get_city_mapping()

#2ã€è·å–å’Œé£å¤©æ°”çš„æ°”è±¡æ•°æ®ï¼Œè¿›è¡Œç›‘æµ‹é¢„è­¦
st.sidebar.header('æ°”è±¡æ•°æ®ç›‘æµ‹')
col7,col8=st.sidebar.columns(2)
city=col8.selectbox('é€‰æ‹©',st.session_state.city_mapping.keys(),
                          index=st.session_state.random_city_index,label_visibility="collapsed")
col7.markdown(time.strftime('%Y-%m-%d %H:%M:%S'))
data_updateTime,df_forecastHours=get_city_weather(st.session_state.city_mapping[city])
index=['æ¸©åº¦','ç›¸å¯¹æ¹¿åº¦','é£é€Ÿ','é™æ°´'] #æŒ‡æ ‡
standard=['18â„ƒï½20â„ƒ','40ï¼…ï½60ï¼…','0m/sï½4m/s','2mmï½4mm'] #æ ‡å‡†å€¼
limit=[18,20,40,60,0,4,2,4]
present=[df_forecastHours.iloc[0][1],df_forecastHours.iloc[0][2],
         round((float(df_forecastHours.iloc[0][4])/3.6),1),df_forecastHours.iloc[0][5]]
monitor=[] #é¢„è­¦
for i in range(4):
    tem={}
    tem['æŒ‡æ ‡']=index[i]
    tem['æ ‡å‡†å€¼']=standard[i]
    tem['å½“å‰å€¼']=present[i]
    if float(present[i])<limit[2*i]:
        judge='åä½'
    elif float(present[i])>limit[2*i+1]:
        judge='åé«˜'
    else:
        judge='æ­£å¸¸'
    tem['é¢„è­¦']=judge
    monitor.append(tem)
df_monitor=pd.DataFrame(monitor,columns=['æŒ‡æ ‡','æ ‡å‡†å€¼','å½“å‰å€¼','é¢„è­¦']) #åˆ›å»ºDataFrame
st.sidebar.dataframe(monitor) #æ˜¾ç¤ºæ•°æ®

#3ã€è§†é¢‘ç›‘æ§+ç‰©ä½“æ£€æµ‹åŠŸèƒ½
st.sidebar.header("è§†é¢‘ç›‘æ§ç‚¹")
confidence_threshold = st.sidebar.slider(
    "ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, DEFAULT_CONFIDENCE_THRESHOLD, 0.05
)
with st.sidebar.container():
    webrtc_ctx=webrtc_streamer(
        key="object-detection",
        mode=WebRtcMode.SENDRECV,
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        video_frame_callback=callback,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True
    )
if st.sidebar.checkbox("æ˜¾ç¤ºæ£€æµ‹ç»“æœ", value=True):
    if webrtc_ctx.state.playing:
        labels_placeholder = st.sidebar.empty()
        # NOTE: The video transformation with object detection and
        # this loop displaying the result labels are running
        # in different threads asynchronously.
        # Then the rendered video frames and the labels displayed here
        # are not strictly synchronized.
        while True:
            try:
                result = result_queue.get(timeout=1.0)
            except queue.Empty:
                result = None
            labels_placeholder.table(result)

#4ã€æ™ºèƒ½åŒ–èŒ¶å›­ç®¡ç†ç³»ç»Ÿ
st.header('æ™ºèƒ½åŒ–èŒ¶å›­ç®¡ç†ç³»ç»Ÿ:tea:')
st.markdown('<br>', unsafe_allow_html=True)#htmlè¯­å¥ï¼Œæ¢è¡Œ

#5ã€èŒ¶å›­æ•°æ®
col1,col2,col3,col4=st.columns(4)
col1.metric("èŒ¶å›­ç§æ¤é¢ç§¯:mountain:","35(ä¸‡äº©)",delta=None)
col2.metric("èŒ¶äº§å€¼:moneybag:","180(äº¿å…ƒ)","0.02%")
col3.metric("èŒ¶äº§é‡:chart_with_upwards_trend:","8.2(ä¸‡å¨)","0.35%")
col4.metric("èŒ¶å†œğŸ‘¨â€ğŸŒ¾","36(ä¸‡äºº)",delta=None)

#6ã€æ°”è±¡æ•°æ®å¯è§†åŒ–
with st.container():
    # è·å–xè½´
    data=df_forecastHours['fxTime']
    x_data=[]
    for i in range(len(data)):
        x_data.append(''.join(re.findall(r'T(.*)\+',data[i])))
    bar = (
        Bar()
        .add_xaxis(x_data)
        .add_yaxis(
            "ç›¸å¯¹æ¹¿åº¦",
            list(map(eval,df_forecastHours['humidity'].values.tolist())),
            yaxis_index=0,
            color="#d14a61",

        )
        .add_yaxis(
            "é™æ°´é‡",
            list(map(eval,df_forecastHours['precip'].values.tolist())),
            yaxis_index=1,
            color="#5793f3",

        )
        .extend_axis(
            yaxis=opts.AxisOpts(
                name="é™æ°´é‡",
                type_="value",
                min_=0,
                max_=5,
                position="right",
                axisline_opts=opts.AxisLineOpts(
                    linestyle_opts=opts.LineStyleOpts(color="#d14a61")
                ),
                axislabel_opts=opts.LabelOpts(formatter="{value} mm"),
            )
        )
        .extend_axis(
            yaxis=opts.AxisOpts(
                type_="value",
                name="æ¸©åº¦",
                min_=-5,
                max_=20,
                position="left",
                axisline_opts=opts.AxisLineOpts(
                    linestyle_opts=opts.LineStyleOpts(color="#675bba")
                ),
                axislabel_opts=opts.LabelOpts(formatter="{value} Â°C"),
                splitline_opts=opts.SplitLineOpts(
                    is_show=True, linestyle_opts=opts.LineStyleOpts(opacity=1)
                ),
            )
        )
        .set_global_opts(
            yaxis_opts=opts.AxisOpts(
                name="ç›¸å¯¹æ¹¿åº¦",
                min_=0,
                max_=100,
                position="right",
                offset=80,
                axisline_opts=opts.AxisLineOpts(
                    linestyle_opts=opts.LineStyleOpts(color="#5793f3")
                ),
                axislabel_opts=opts.LabelOpts(formatter="{value} ï¼…"),
            ),
            title_opts=opts.TitleOpts(title=None),
            tooltip_opts=opts.TooltipOpts(trigger="axis", axis_pointer_type="cross"),
            legend_opts=opts.LegendOpts(is_show=True,textstyle_opts=opts.TextStyleOpts(color='#fafafa'),item_gap=20,
                                        pos_left='10%',pos_right='90%'),
            xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(color='#fafafa')),
            datazoom_opts=opts.DataZoomOpts(
                type_="inside",
                range_start=0,
                range_end=100),
        )
    )
    line = (
        Line()
        .add_xaxis(x_data)
        .add_yaxis(
            "æ¸©åº¦",
            list(map(eval,df_forecastHours['temp'].values.tolist())),
            yaxis_index=2,
            color="#675bba",
            label_opts=opts.LabelOpts(is_show=False),
        )
        .set_series_opts(label_opts=opts.LabelOpts(is_show=True))
    )
    bar.overlap(line)
    grid = Grid()
    grid.add(bar, opts.GridOpts(pos_left="5%", pos_right="20%"), is_control_axis_index=True)
    components.html(grid.render_embed(), width=1400, height=520)

col5,col6=st.columns(2)
with col5.container():
    x = df_forecastHours['windDir'].values.tolist()
    y = list(map(eval, df_forecastHours['windSpeed'].values.tolist()))
    y_data = []
    for i in range(len(y)):
        y_data.append(round(float(y[i]) / 3.6, 1))#km/hä¸m/så•ä½æ¢ç®—
    #é…è‰²æ–¹æ¡ˆä»EchartsæŠ•è¿‡æ¥ï¼Œå¾„å‘æ¸å˜
    radial_item_color_js = """new echarts.graphic.RadialGradient(0, 0, 1, [{
                                            offset: 0,
                                            color: 'rgb(251, 118, 123)'
                                        }, {
                                            offset: 1,
                                            color: 'rgb(204, 46, 72)'
                                        }])"""
    c = (
        Polar(init_opts=opts.InitOpts(width='400px',height='400px'))
        .add_schema(angleaxis_opts=opts.AngleAxisOpts(data=x, type_="category",
                                                      axislabel_opts=opts.LabelOpts(color='#fafafa'),
                                                      axistick_opts=opts.AxisTickOpts(is_show=True)),
                    radiusaxis_opts=opts.RadiusAxisOpts(axislabel_opts=opts.LabelOpts(color='#fafafa'))
                    )
        .add("é£é€Ÿ", y_data, type_="bar", stack="stack0")
        # .set_series_opts(label_opts=opts.LabelOpts(is_show=True,color='#ffffff',position='inside'))
        # .set_series_opts(itemstyle_opts=opts.ItemStyleOpts(color=JsCode(radial_item_color_js)))
        .set_global_opts(
            title_opts=opts.TitleOpts(title="é£ç«ç‘°å›¾",
                                      title_textstyle_opts=opts.TextStyleOpts(color='#fafafa')),
            legend_opts=opts.LegendOpts(is_show=True, pos_left='70%',
                                        pos_right='30%',
                                        textstyle_opts=opts.TextStyleOpts(color='#fafafa')),
        )
    )
    components.html(c.render_embed(),height=390,width=400)

with col6.container():
    x_tea=["æ¼³å¹³æ°´ä»™","èŒ‰è‰èŠ±èŒ¶","å¦æ´‹å·¥å¤«","ç™½èŠ½å¥‡å…°","é‡‘éªçœ‰","æ­¦å¤·å²©èŒ¶"]
    y_num=random.sample([i for i in range(30000,150000)],6)
    data_pair=[]
    for k, v, c in zip(x_tea, y_num, ["#5470c6","#91cc75","#fac858","#ee6666","#73c0de","#fc8452"]):
        data_pair.append(
            opts.BarItem(
                name=k,
                value=v,
                itemstyle_opts=opts.ItemStyleOpts(color=c)
            ))
    c_tea = (
        Bar(init_opts=opts.InitOpts(width='600px',height='400px'))
        .add_xaxis(x_tea)
        .add_yaxis('',data_pair)
        .reversal_axis()
        .set_series_opts(label_opts=opts.LabelOpts(position="right"))
        .set_global_opts(title_opts=opts.TitleOpts(title="ç§æ¤å“ç§åˆ†æ",pos_left='center',pos_top='top',
                                                   title_textstyle_opts=opts.TextStyleOpts(color='#fafafa')),
                         yaxis_opts=opts.AxisOpts(axisline_opts=opts.AxisLineOpts(linestyle_opts=opts.LineStyleOpts(color='#ffffff'),is_show=False),
                                                  name="é¢ç§¯/äº©",
                                                  axistick_opts=opts.AxisTickOpts(is_show=False)),
                         xaxis_opts=opts.AxisOpts(axisline_opts=opts.AxisLineOpts(is_show=False),
                                                  axistick_opts=opts.AxisTickOpts(is_show=False),
                                                  axislabel_opts=opts.LabelOpts(is_show=False)),
                         toolbox_opts=opts.ToolboxOpts(is_show=True,
                                                       orient='horizontal',
                                                       feature={"saveAsImage": {},"dataZoom":{"yAxisIndex": "none"},"restore":{},
                                                                "magicType":{"show": True, "type":["line","bar"]},"dataView": {}},
                                                       pos_left='center',
                                                       pos_top='5%'
                                                       ))
    )
    components.html(c_tea.render_embed(), height=350, width=800)
st.markdown('<br>', unsafe_allow_html=True)#htmlè¯­å¥ï¼Œæ¢è¡Œ
#7ã€èŒ¶å›­æ–‡å­—ä»‹ç»
st.markdown("### å¤§ç”°ç¾äººæ™¯åŒºèŒ¶å›­")
st.markdown('<br>', unsafe_allow_html=True)#htmlè¯­å¥ï¼Œæ¢è¡Œ
st.markdown(
    """ 
    &emsp;&emsp;å¤§ä»™å³°èŒ¶ç¾äººæ™¯åŒºä½äºç¦å»ºçœå¤§ç”°å¿å±å±±ä¹¡ï¼Œå åœ°é¢ç§¯çº¦3000äº©ï¼Œæ˜¯å›½å†…é¦–å®¶ä»¥â€œé«˜å±±èŒ¶â€ä¸ºä¸»é¢˜ï¼Œèæ–‡åŒ–ä½“éªŒã€ç¯å¢ƒæ•™è‚²ã€æ–‡åˆ›å±•ç¤ºã€ä¼‘é—²åº¦å‡ç­‰åŠŸèƒ½ä¸ºä¸€ä½“çš„åŸç”Ÿæ€æ™¯åŒºã€‚
                          
    &emsp;&emsp;å¤§ç”°çš„èŒ¶è´¸å†å²æ‚ ä¹…ï¼Œå¯è¿½æº¯åˆ°å—å®‹éš†å…´äºŒå¹´(1164å¹´)ï¼Œå¤§ç”°ç§æ¤é«˜å±±èŒ¶å§‹äºå¤§ä»™å³°å´‡åœ£å²©å¯ºåƒ§äººç§èŒ¶ï¼Œã€Šåº·ç†™å­—å…¸ã€‹ä¸­å°±æœ‰å¯¹å¤§ç”°èŒ¶å¶ç”Ÿäº§çš„æ³¨è§£ã€‚ç»è¿‡æ•°ä»£èŒ¶äººä¸æ‡ˆçš„ä¼ æ‰¿è€•è€˜ï¼Œå¤§ç”°å…¨å¿ç°æœ‰é«˜å±±èŒ¶å›­è¿‘10ä¸‡äº©ï¼Œäº§å€¼7.19äº¿å…ƒï¼Œæ¶‰èŒ¶äººå‘˜6.3ä¸‡ä½™äººã€‚
      
    &emsp;&emsp;å¤§ç”°ä¸ä»…æœ‰â€œä¸­å›½é«˜å±±ç¡’è°·â€ä¹‹ç§°ï¼Œè¿˜æ˜¯å…¨å›½å”¯ä¸€çš„â€œä¸­å›½é«˜å±±èŒ¶ä¹‹ä¹¡â€ï¼Œç‰¹åˆ«æ˜¯ï¼Œå¤§ç”°æµ·æ‹”åƒç±³ä»¥ä¸Šçš„å±±å³°æœ‰175åº§ï¼Œæ˜¯é—½æ±Ÿã€ä¹é¾™æ±Ÿã€æ™‹æ±Ÿä¸‰å¤§æ°´ç³»æ”¯æµçš„å‘æºåœ°ï¼Œè¢«åˆ—
    ä¸ºç¦å»ºçœçº§é‡ç‚¹ç”Ÿæ€åŠŸèƒ½åŒºã€‚å¿åŸŸå†…èŒ¶å›­å¹¿å¸ƒï¼Œç”±äºå¤§ç”°é«˜å±±äº‘é›¾å¤šï¼Œæ¼«å°„å…‰è¾ƒå¤šï¼ŒèŒ¶æ ‘èŠ½å¤´è‚¥å£®ã€å¶è´¨æŸ”è½¯ã€èŒ¸æ¯›ç”šå¤šï¼Œæ°¨åŸºé…¸ã€å’–å•¡ç¢±ã€èŠ³é¦™æ²¹ç­‰ç‰©è´¨ç§¯ç´¯è¾ƒå¤šï¼Œä»¥æ­¤
    åŠ å·¥æˆçš„é«˜å±±èŒ¶å½¢ç¾å‘³æµ“ã€æ»‹å‘³ç”˜é†‡ï¼Œå¹¶ä¸”æ¯”è¾ƒè€æ³¡ã€‚
    
    &emsp;&emsp;ä»¥å¤§ç”°å°¤ä¸ºçŸ¥åçš„â€œæ±Ÿå±±ç¾äººèŒ¶â€ä¸ºä¾‹ï¼Œå…¶ç‰¹åˆ«ä¹‹å¤„åœ¨äºï¼ŒèŒ¶é’å¿…é¡»æ˜¯å°ç»¿å¶è‰å®å’¬å¸é£Ÿè¿‡ï¼Œå°ç»¿å¶è‰åœ¨èŒ¶é’ä¸Šåˆ†æ³Œæ°´è§£é…¶ï¼Œåˆæˆèœçƒ¯é†‡ï¼ŒæŒ¥å‘å‡ºèœœç³–é¦™æ°”ï¼Œè¿™æ˜¯ç¾äººèŒ¶é†‡
    åšæœé¦™èœœå‘³çš„æ¥æºï¼Œä¹Ÿæ˜¯å…¶æœ‰åˆ«äºå…¶å®ƒèŒ¶æœ€æ˜¾è‘—çš„åœ°æ–¹ã€‚   
    """
    )
#8ã€èŒ¶å›­æ— äººæœºå½±åƒ
st.image("./picture/ç¦å»ºå¤§ç”°å¿å¤§ä»™å³°èŒ¶ç¾äººæ™¯åŒºèŒ¶å›­.jpg",caption="å¤§ä»™å³°èŒ¶ç¾äººæ™¯åŒºèŒ¶å›­")
st.markdown('<br>', unsafe_allow_html=True)#htmlè¯­å¥ï¼Œæ¢è¡Œ
#9ã€èŒ¶å›­è§†é¢‘ä»‹ç»
st.markdown("### èŒ¶å›­è§†é¢‘ä»‹ç»")
st.markdown('<br>', unsafe_allow_html=True)#htmlè¯­å¥ï¼Œæ¢è¡Œ
col11,col12=st.columns(2)
video11,video12=get_video_byte()
col11.video(video11, format='video/mp4',start_time=1)
col12.video(video12, format='video/mp4',start_time=9)
#æºä»£ç 
with st.expander("View Code"):
    with open('webStreamlit.py', 'r', encoding='utf-8') as f:
        code = f.read()
    st.code(code, language="python")
